{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df81682e",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5923b9",
   "metadata": {},
   "source": [
    "Note: This notebook should be run from the `high-order-anesthesia` folder to ensure the correct imports and file paths are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39a20a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now in: high-order-anesthesia\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "TARGET_DIR_NAME = \"high-order-anesthesia\"\n",
    "def ensure_project_root(target_name: str = \"high-order-anesthesia\") -> Path:\n",
    "    cwd = Path.cwd().resolve()\n",
    "    if cwd.name == target_name:\n",
    "        return cwd\n",
    "    for parent in cwd.parents:\n",
    "        if parent.name == target_name:\n",
    "            os.chdir(parent)\n",
    "            return parent\n",
    "    raise RuntimeError(\n",
    "        f\"Could not find '{target_name}' in current path or parents. \"\n",
    "        f\"Please run the notebook from inside the project.\"\n",
    "    )\n",
    "ROOT = ensure_project_root(\"high-order-anesthesia\")\n",
    "print(f\"Now in: {ROOT.name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be12047b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\CAMILO\\Brain_Entropy\\REPO\\.high_order_anesthesia_repo\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import itertools\n",
    "import logging\n",
    "from tqdm.notebook import tqdm, trange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82db3e4",
   "metadata": {},
   "source": [
    "Custom Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "149296e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hoi_anesthesia.thoi_utils import simulated_annealing_parallel\n",
    "from src.hoi_anesthesia.utils import max_difference_pairs\n",
    "from src.hoi_anesthesia.io import load_covariance_dict, print_time\n",
    "from src.hoi_anesthesia.plotting import plot_measures_accross_states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6d9345",
   "metadata": {},
   "source": [
    "#### Data loading and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba96c1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = \"results\"\n",
    "\n",
    "# Load covariance matrices\n",
    "all_covs = load_covariance_dict(f\"{results_path}/covariance_matrices_gc.h5\")\n",
    "\n",
    "# States for each dataset; MA: Multi-anesthesia - DBS: Deep Brain Stimulation\n",
    "conscious_states = {\n",
    "    \"MA\": [\"MA_awake\"],  \n",
    "    \"DBS\": [\"DBS_awake\", \"ts_on_5V\"],\n",
    "}\n",
    "nonresponsive_states = {\n",
    "    \"MA\": [\"ts_selv2\", \"ts_selv4\", \"moderate_propofol\", \"deep_propofol\", \"ketamine\"],\n",
    "     \"DBS\": [\"ts_off\", \"ts_on_3V_control\", \"ts_on_5V_control\"],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c029ab67",
   "metadata": {},
   "source": [
    "#### Simulated Annealing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "473d5f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = 1000\n",
    "max_iter = 10000\n",
    "repeat = 100\n",
    "batch_size = 300\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be58df92",
   "metadata": {},
   "source": [
    "#### Select dataset and orders to optimize \n",
    "The script saves a checkpoint csv at each order so the execution can be interrupted without losing all of the work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e380dbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_to_optimize = ['DBS', 'MA']\n",
    "orders = [3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d2d2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************\n",
      "ORDER: 3\n",
      "Evaluating DBS_awake vs ts_off with 1008 pairs for task: Cpos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]                            \n",
      "Processing n-plets:  57%|█████▋    | 57/100 [00:00<00:00, 561.59it/s] "
     ]
    }
   ],
   "source": [
    "for selected_dataset in datasets_to_optimize:\n",
    "    t_i = time.time()\n",
    "    for order in orders:\n",
    "        results = []\n",
    "        print(\"*\" * 30)\n",
    "        print(\"ORDER:\", order)\n",
    "        # Iterate over dataset/state combinations\n",
    "        for state_c, state_nr in itertools.product(\n",
    "            conscious_states[selected_dataset], nonresponsive_states[selected_dataset]\n",
    "        ):\n",
    "            covs_c = all_covs[selected_dataset][state_c]  # shape (N_c, 82, 82)\n",
    "            covs_nr = all_covs[selected_dataset][state_nr]  # shape (N_nr, 82, 82)\n",
    "            for target_task in [\"Cpos\", \"NRpos\"]:\n",
    "                torch.cuda.empty_cache()\n",
    "                cov_list = []\n",
    "                subject_indices = []\n",
    "                for i in range(covs_c.shape[0]):\n",
    "                    for j in range(covs_nr.shape[0]):\n",
    "                        cov_c = torch.from_numpy(covs_c[i])  # 82x82\n",
    "                        cov_nr = torch.from_numpy(covs_nr[j])  # 82x82\n",
    "                        if target_task == \"Cpos\":\n",
    "                            cov_list.append(torch.stack([cov_c, cov_nr], dim=0))\n",
    "                        elif target_task == \"NRpos\":\n",
    "                            cov_list.append(torch.stack([cov_nr, cov_c], dim=0))\n",
    "                        subject_indices.append([i, j])\n",
    "\n",
    "                X = torch.stack(cov_list, dim=0).to(device)\n",
    "                n_batches = X.shape[0] // batch_size + 1\n",
    "                t_x = time.time()\n",
    "                print(\n",
    "                    f\"Evaluating {state_c} vs {state_nr} with {X.shape[0]} pairs for task: {target_task}\"\n",
    "                )\n",
    "                for idx in range(n_batches):\n",
    "                    batched_X = X[idx * batch_size : (idx + 1) * batch_size, ...]\n",
    "                    batched_sub_indices = subject_indices[\n",
    "                        idx * batch_size : (idx + 1) * batch_size\n",
    "                    ]\n",
    "                    torch.cuda.empty_cache()\n",
    "                    optimal_nplets, optimal_scores = simulated_annealing_parallel(\n",
    "                        X=batched_X,\n",
    "                        order=order,\n",
    "                        device=device,\n",
    "                        largest=True,\n",
    "                        metric=max_difference_pairs,\n",
    "                        repeat=repeat,\n",
    "                        early_stop=early_stop,\n",
    "                        max_iterations=max_iter,\n",
    "                        covmat_precomputed=True,\n",
    "                        batch_size=batch_size,\n",
    "                        verbose=logging.WARNING,\n",
    "                    )\n",
    "                    max_idx = torch.argmax(optimal_scores, dim=0)  #\n",
    "\n",
    "                    best_nplets = optimal_nplets[\n",
    "                        max_idx, torch.arange(optimal_nplets.size(1))\n",
    "                    ]\n",
    "                    best_scores = optimal_scores[\n",
    "                        max_idx, torch.arange(optimal_scores.size(1))\n",
    "                    ]\n",
    "\n",
    "                    for best_score, best_nplet, sub_indices in zip(\n",
    "                        best_scores, best_nplets, batched_sub_indices\n",
    "                    ):\n",
    "                        best_nplet = best_nplet.tolist()\n",
    "                        best_nplet.sort()\n",
    "                        dataset_c = selected_dataset\n",
    "                        dataset_nr = selected_dataset\n",
    "                        subject_c, subject_nr = sub_indices\n",
    "\n",
    "                        results.append(\n",
    "                            {\n",
    "                                \"order\": order,\n",
    "                                \"task\": target_task,\n",
    "                                \"state_c\": state_c,\n",
    "                                \"state_nr\": state_nr,\n",
    "                                \"subject_c\": subject_c,\n",
    "                                \"subject_nr\": subject_nr,\n",
    "                                \"optimal_nplet\": best_nplet,\n",
    "                                \"optimal_score\": best_score.item(),\n",
    "                            }\n",
    "                        )\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                results_df = pd.DataFrame(results)\n",
    "                results_df.to_csv(\n",
    "                    f\"{results_path}/R1_A_max_O_diff_{selected_dataset}_{order}.csv\",\n",
    "                    index=False,\n",
    "                    encoding=\"utf-8-sig\",\n",
    "                    sep=\";\",\n",
    "                    decimal=\",\",\n",
    "                )\n",
    "                t_y = time.time()\n",
    "                print(\n",
    "                    f\"{X.shape[0]} pairs evaluated in:\",\n",
    "                    np.round(t_y - t_x, 1),\n",
    "                    \"seconds\",\n",
    "                )\n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df.to_csv(\n",
    "            f\"{results_path}/R1_A_max_O_diff_{selected_dataset}_{order}.csv\",\n",
    "            index=False,\n",
    "            encoding=\"utf-8-sig\",\n",
    "            sep=\";\",\n",
    "            decimal=\",\",\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c456a66a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".high_order_anesthesia_repo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
